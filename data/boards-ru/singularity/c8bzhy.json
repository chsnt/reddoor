{"subreddit":{"display_name":"singularity"},"subreddit_loc":"singularity","selftext":"This is not 100% comprehensive, but I do want to do my part to clear up some misconceptions and myths involving a few areas of technology. \n\n**Myth**: *\"Androids that look indistinguishable from humans are decades away\"*\n\n**Fact**: We can already create constructs indistinguishable from humans. It's a style known as \"*[hyperrealism](https://en.wikipedia.org/wiki/Hyperrealism_\\(visual_arts\\))*\" and has been around since the 1970s. [As seen here](https://imgur.com/gallery/MCGvz) and even [here with this animatronic](https://www.youtube.com/watch?v=26fLK9m4eNE). Why do gynoids like Sophia and Actroid look so offputting and stuck in the Uncanny Valley if it's possible to create almost 100% human-indistinguishable sculptures? One: because it's *expensive*. ***Very*** expensive. It can cost tens to hundreds of thousands of dollars just to create one ultra-realistic robot. If you're a laboratory, you'd probably rather spend that on the underlying mechanics, which are also very expensive. And that leads me to two: **robotics/animatronics are not fluid enough to properly utilize perfect realism**. We're still getting closer, true, but we're going to need advanced artificial muscles to really get there. This is why robots like Geminoids look so off-putting despite looking so realistic. \n\nA better statement would be \"androids that *move* indistinguishably from humans are decades away\".\n\n\n**Myth**: *\"There are only three types of AI: weak/narrow AI, strong/general AI, and super AI\"*\n\n**Fact**: There are actually four. If you want to get really pretentious, you could increase that number further, but four is the number that would accurately describe all possible AI architecture. Narrow AI is what we've had since the 1940s and have struggled to progress beyond. General AI is the dream, and super AI is \"the Singularity\". However, there is one other category, one which lies between narrow and general AI. However, since we've struggled just to improve narrow AI for almost a century, we've never bothered to give this type a name. I've come to call it \"expert artificial intelligence\" (or XAI, or AXI). For ease, I'll use that designation in this post. This type of AI involves taking a narrow root capability and then sprouting it into a multipurpose agent, a system able to do more than one very narrow task. Sort of like an actual expert, who is educated in a specific area and can do all of the individual tasks in that area. If an ANI is single-purpose and AGI is general-purpose, then AXI is multi-purpose. If you want an example of an AXI, [look no further than transformers like GPT-2](https://radiomonkeys.org/2019/06/30/gpt-3-as-proto-agi-or-axi/).\n\n**Myth**: *\"We are decades away from having general-purpose robots\"*\n\n**Fact**: Much like lifelike robots, we have long possessed the hardware necessary for general-purpose robots. The original ASIMO, released in 2000, could have been a domestic robot capable of all mundane tasks promised by science fiction. Atlas, too, is already home and business-capable. There were even some robots from the 1980s and '90s that could have played the role of domestobots. Why didn't they? Again, it all comes down to AI. We may have general-purpose robots, but we obviously lack general-purpose AI to act as the brains. Computers struggled with image recognition and visual processing for an entire lifetime— someone born at the dawn of digital computing in the 1940s could have worked their entire life on this singular field and died of old age before computers became even remotely competent at not bumping into objects just to move around. Hence why driverless cars are now a thing. However, spatial & image recognition are just two areas in a *very* wide range of requirements to act in an environment. Another bottleneck is power. [The original ASIMO from 2000 could only run for 30 minutes](https://www.youtube.com/watch?v=82JFCciO3E4), making its utility very questionable. The last iteration of ASIMO from 2014 had improved that to about an hour. Until robots can work for at least 6 hours without recharging (or can constantly wirelessly recharge), we are unlikely to see general-purpose models even with general AI. Basically it's a case of the hardware preempting the software/applications, like inventing a car before you've invented the engine. So once again, a better way of describing this myth is **general-purpose robots require general-purpose AI, which is likely decades away**.\n\n**Myth**: *\"Digital assistants like Alexa qualify as AGI (or AXI)\"*\n\n**Fact**: While these kinds of AIs are impressive, they are not generalized at all. They merely *appear* so because they are essentially ensembles of many narrow AIs together. And unlike a brain, they don't even work together to improve each other. They're little more than if-then statements connected to other if-then statements, with some voice recognition and chatbot capabilities thrown in. While they are very *accurate* and quite strong for narrow AI, they are no more signs of the Singularity and general AI than Wolfram Alpha.\n\n**Myth**: *\"Flying cars are impossible because they're too wasteful and humans can barely drive on a 2D plane, let alone fly on a 3D one\"*\n\n**Fact**: The energy intensity is roughly true— making something fly is always going to cost more energy than making it roll, even in a world with perfect batteries and room-temperature superconductors. However, [passenger drones](https://en.wikipedia.org/wiki/Passenger_drone) render the need for pilots' licenses moot. In the near future, there will likely be drone taxi services utilizing passenger drones [in a manner very similar to the long-awaited visions of flying cars](https://i.imgur.com/HfFnPTu.gifv). \n\n**Myth**: *\"Designer babies are decades away\"*\n\n**Fact**: [The first designer babies were born last year in China](https://en.wikipedia.org/wiki/Lulu_and_Nana_controversy). Their genes were selectively targeted to make them resistant to HIV, and this also likely gave them increased intelligence as a result (but possibly also other unknown diseases). I've seen some say that the controversy was due to the implications that this would *lead to* designer babies when the truth is that these two *are* designer babies. The technology is absolutely not beyond us, and if you're willing to forgo ethics (and possibly skip to China), you could be the parent of a designer baby today. \n\n**Myth**: *\"We could have created moon bases in the 1970s if we had more funding\"*\n\n**Fact**: I regard the moon landings as the \"Antiquity period\" of active space travel, the space exploration equivalent of the Antikythera Mechanism & Hero's steam engine— something we did long ago that was possible with the technology of the era but could not be meaningfully expanded upon. The cost of creating a moon base in the 1960s & '70s would have been so extreme that it could have bankrupted the planet several times over. Because think about what that would require: you'd need *constant and regular* trips back and forth, cycling staff and materials; you'd need on-site manufacturing on the surface; you'd need protection in order to stave off micrometeors (and occasionally larger objects); you'd need habitat regulation systems powered by artificial intelligence far more advanced than anything that could have possibly existed at the time; you'd need doctors, physicians, engineers, conflict counselors, psychiatrists, and much more— all this alone would have run costs upwards of something similar to what the Iraq War cost us, in a society where science funding is determined by senators and representatives listening to their notoriously fickle constituents and notoriously greedy lobbyists rather than actual budgeting directors. The regular trips to and from the moon alone would probably cost $100 billion a week. Lunar colonization will only happen when additive manufacturing (i.e. 3D & 4D printing), general-purpose robotics, and regular commercial space travel have been mastered. Once SpaceX and Blue Origin bring down the cost of transporting things into space, we then need advanced 3D printers and utility robots to actually assist with constructing those colonies and their materials, and then we'll need AI to monitor the colonists and make sure they're not going insane or wasting away. Yet again, this is an example of the car coming before the engine.\n\n**Myth**: *\"Automation is going to unemploy millions in the 2020s, starting with the fast-food and factory jobs*\n\n**Fact**: While true that automation is currently overblown as a risk (and it comes back to AI, which I'll get to shortly), that doesn't mean it's not going to become a thing. The real myth here is that it's going to impact blue-collar and entry-level physical jobs first. Whenever you see news articles and econ-blog posts of automation, it's invariably depicting robots in warehouses or trying to flip burgers when the cold fact is that the entertainment, data-management, journalistic, and white-collar jobs will be the first to be automated. See /r/MediaSynthesis for what I mean on this front, and it all comes down to a corollary: to automate data-based jobs (i.e. things that can be reduced to pixel data), you need only AI (and not even general AI). To automate physical jobs, you need general AI + robotics. In the 2020s, if I want a cartoon to watch or an entire scene of musical artists to listen to, I could get a synthesizer AI to generate it all for me; if I need to pick up trash in my yard, I'm going to need a robot either specially designed for picking up trash or generally able to do such a task. The former costs little to nothing except to run; you can already use media synthesis networks right now in your browser. The latter might cost tens of thousands of dollars just to do a single task. Likewise, generating news articles is certainly within the capability of artificial neural networks. Right now, you can only give them prompts and they'll spit out their own creative interpretation that has no basis in reality. In the near future, you may be able to feed them extra links as sources, allowing them to parse through the contents and spin the details. Or you could direct them to look for a news story from certain keywords, making them do all the work. Similar deal with modeling: you could pay thousands for a professional model, or you could get an AI-generated model, even feeding it images of clothes that it will then instantly wear. And so on and so forth. Only really technical and specialized information (such as instruction manuals), autobiographies, & purely artistic fiction may remain by *2025*. And again, you do not need AGI for any of this; AXI is good enough. In fact, I'd argue this tech is how we got AXI in the first place. Deepfakes aren't AXI, but things like GPT-2 are.\n\n**Myth**: *\"The Future™ has consistently failed to materialize before now, so past predictions aren't going to start suddenly coming true in the next [X] years\"*\n\n**Fact**: Think of so many technologies science fiction predicted we'd have either by now or in the near future. Flying cars, domestic robots, personalized media, gene therapies, augmented reality, space colonies, autonomous vehicles, cybernetics, and so much more. What's the common denominator above them all? *They all require extensive research and agents constantly working on them.* Golden age, even some cyberpunk-era science fiction severely overestimated the ability of humans to make these things work. In many cases, it was because of unconscious desires to set those eras (or idealized versions of those eras) in the future. Hence why, in 1950s sci-fi serials, you often had dashing scientific leads exploring uncharted worlds in galaxy-hopping spacecrafts that were still staffed entirely by humans, required human engineers, and often had women still playing purely domestic roles, with a ship AI mainly providing the most basic operational services. Or how in most sci-fi that features flying cars, even up to the present day, you'll still see human pilots of those flying cars as they engage in ridiculously dangerous maneuvers. It's sexier and more dramatic (and more individualistic) than simply being ferried by drone. \n\nThe truth is that most of this tech is being designed to *remove us from the equation*. And that's because it's the *only way a lot of this tech can work*. Humans get distracted, tired, biased, and much more. We *need* computers to control flying cars if we want flying cars at all. We *need* computers to figure out things [like how proteins fold](https://www.sciencemag.org/news/2018/12/google-s-deepmind-aces-protein-folding) if we want even more advanced genetic engineering. We *need* computers to parse through petabytes of medical data if we want them to be doctors and cure things like cancer & AIDS. We *need* computers to be strong enough to run the networks that allow for domestic utility & service robots. We *need* computers to figure out the most efficient designs for things like hyperloops and vactrains. We *need* computers to run additive manufacturing centers if we want true abundance and space colonization. We *need* computers to become strong enough if we want things like the internet of things, augmented reality, smart roads, molecular nanotech, transhumanism, and more to be realized. Once the hardware is there, the software will follow very quickly.\n\n**Myth**: *We're approaching an era of computational stagnation*\n\n**Fact**: Technically, we're *already* in an era of computational stagnation. Moore's Law gave out years ago. However, that doesn't mean the Future™ has been canceled. Ray Kurzweil has used Moore's Law to point out exponential (read: logarithmic) growth in computational capabilities for decades, so many detractors now claim that he was riding *solely* on Moore's Law to get us to AGI. As far back as the '90s, he claimed Moore's Law was going to break down right about now and we'd spend about a decade waiting for a new paradigm or a major refinement to an old one. And that also doesn't necessarily mean there's no major improvements in AI either. Just the opposite: [the amount of compute used to run the hardest networks has increased by *well* over 300,000x since 2012](https://blog.openai.com/ai-and-compute/). Note: that doesn't necessarily mean AI is over 300,000x more advanced than it was in 2012, just that we are able to do things in near-real time now that would have taken days, even weeks or months to run back then.","title":"Clearing up some misconceptions about certain future tech (e.g. realistic androids, AI, robotics, etc.)","subreddit_name_prefixed":"r/singularity","ups":31,"created":1562116888,"link_flair_background_color":"","id":"c8bzhy","author":{"name":"Yuli-Ban"},"permalink":"/r/singularity/comments/c8bzhy/clearing_up_some_misconceptions_about_certain/","url":"https://www.reddit.com/r/singularity/comments/c8bzhy/clearing_up_some_misconceptions_about_certain/","created_utc":1562088088}