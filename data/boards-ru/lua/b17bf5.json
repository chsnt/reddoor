{"subreddit":{"display_name":"lua"},"subreddit_loc":"принимать","selftext":"У меня было приложение, которое я запускал на экземпляре aws p2.xlarge (графический процессор Tesla K80), и я хотел бы запустить приложение на экземпляре p3.2xlarge (графический процессор Volta).\n\nИзвините, если эти вопросы показывают, что я не знаю, что делаю, я немного новичок в экосистеме lua / torch / luajit / cuda\n\nПриложение находится в образе докера, поэтому я считаю, что мне нужно смонтировать Cuda Compute Cache в образ докера (я не уверен на 100%, почему luajit не может создать кеш в контейнере докера)\n\n1. Будет ли какой-либо старый каталог tmp работать в качестве кеша вычислений? По умолчанию для Linux используется `~ / .nv / ComputeCache`, но мой хост не имеет этого каталога. Если я использую `/ tmp / myapplicationcache`, это будет хорошо?\n\n2. Я не уверен на 100%, почему luajit не может создать кеш в контейнере Docker. Это потому, что luajit ВСЕГДА будет работать медленно при первом выполнении, а последующие выполнения будут обращаться к скомпилированным библиотекам, таким как cudnn? Насколько я понимаю, кеш также ускорит первое выполнение.\n\n3. Содержит ли кеш cuda специфичные для приложения двоичные файлы или содержит такие вещи, как библиотека компиляции (например, предварительно скомпилированный cudnn)","title":"Использование Luajit, nvidia-docker и Volta. Проблема с CUDA_CACHE_PATH","subreddit_name_prefixed":"r/lua","ups":4,"created":1552633980,"link_flair_background_color":"","id":"b17bf5","author":{"name":"8solutions"},"permalink":"/r/lua/comments/b17bf5/using_luajit_nvidiadocker_and_volta_trouble_with/","url":"https://www.reddit.com/r/lua/comments/b17bf5/using_luajit_nvidiadocker_and_volta_trouble_with/","created_utc":1552605180}